{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17 - Bag of Visual Words\n",
    "\n",
    "Neste roteiro iremos explorar o método Bag of Visual Words para a determinação de similaridade entre imagens. Apesar de existirem métodos prontos no OpenCV iremos implementar partes deste método nós mesmos para fixar melhor os conceitos. \n",
    "\n",
    "**Aviso**: Ao pesquisar sobre este modelo a maioria dos recursos será sobre classificação de imagens, mas ele também é adequado para similaridade de imagens. \n",
    "\n",
    "O OpenCV já possui uma implementação de *Bag of Visual Words* fácil de usar, mas ela esconde detalhes demais do funcionamento do método. Como nosso objetivo é exercitar os conceitos por trás do modelo, criaremos nossa própria versão a partir de funções auxiliares disponibilizadas pelo OpenCV e scikit-learn. No projeto você pode (deve?) usar as funções do OpenCV diretamente. \n",
    "\n",
    "Nosso roteiro é dividido em duas grandes etapas. A primeira etapa, feita nas partes $0-4$ é o **treinamento** do nosso modelo. É nesta etapa que selecionamos um conjunto de imagens para criar nosso vocabulário e que determinamos quantos padrões visuais colocaremos no histograma. Isto é feito com base em um algoritmo de *agrupamento*, que encontre conjuntos de padrões visuais similares. Note que não existe um gabarito que defina qual deve ser a similaridade entre as imagens nem qual o resultado de uma busca. Por isso dizemos que este tipo de modelo é **não-supervisionado**, ou seja, toda informação usada está presente nas próprias imagens. O **treinamento** pode ser um processo lento pois, idealmente, ele é feito somente uma vez. Voltaremos nesse assunto na próxima semana, então você pode prosseguir mesmo que esta explicação não esteja 100% clara. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A segunda etapa é a **aplicação** do modelo treinado para computar similaridades entre imagens. Nesta etapa computamos a representação em histograma de padrões visuais de uma imagem de busca e fazemos a comparação com as imagens do nosso banco de dados. Esta etapa deve ser muito rápida, pois o usuário espera uma resposta rápida de sistemas de busca.\n",
    "\n",
    "# Parte 0 - Instalação do OpenCV e banco de imagens\n",
    "\n",
    "Os trabalhos usando o *Bag of Words* costumam usar os métodos *SIFT* ou *SURF* para extração e descrição de pontos de interesse. Estes métodos são patenteados e para usá-los é necessário  instalar o pacote *opencv-contrib-python*, disponível via *pip*. Por alguma razão a versão mais atual não contém estes métodos, então precisamos instalar uma versão específica ligeiramente mais antiga. \n",
    "\n",
    "**Atenção**: é necessário desinstalar seu opencv antigo antes de instalar este pacote!\n",
    "\n",
    "    > pip install opencv-contrib-python==3.4.0.12\n",
    "\n",
    "Hoje iremos trabalhar com as funções usadas na atividade passsada. Vamos usar também o conjunto de imagens *Caltech101*, disponíveis [aqui](http://www.vision.caltech.edu/Image_Datasets/Caltech101/#Download). \n",
    "\n",
    "# Parte 1 - revisão\n",
    "\n",
    "**Exercício**: crie uma função `def computa_descritores(img)` que recebe uma imagem e devolve os descritores dela. Você deve usar o método `SURF` neste exercício e, como na atividade anterior, pode ignorar as posições de cada ponto de interesse encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import namedtuple\n",
    "import os, sys\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "def computa_descritores(img):\n",
    "    surf = cv2.xfeatures2d.SURF_create()\n",
    "    kp, des = surf.detectAndCompute(img, None)    \n",
    "    return des"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício**: crie uma função `def le_descritores_imagens(pastas, max_items=5)` que recebe uma lista de pastas como argumento, computa os descritores de cada imagem dentro desta pasta e retorna uma tupla contendo uma lista com o caminho todas as imagens analisadas e uma matriz contendo seus descritores. Verifique que a matriz retornada é uma matriz do `numpy` e não uma lista de listas. Para tornar nosso processamento mais rápido, processe somente as 5 primeiras imagens de cada pasta. \n",
    "\n",
    "**Dica**: se não souber como listar os arquivos de um diretório em Python busque pela função `os.listdir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def le_descritores_imagens(pastas, max_items = 5):\n",
    "    list_Names  = []\n",
    "    list_Matrix = []\n",
    "    list_Imgs   = []\n",
    "    Tuple = namedtuple('Tupla', 'listNames, matrix ')\n",
    "    \n",
    "    for pasta in pastas:\n",
    "        dir_Name = \"./proj1/101_ObjectCategories/\" + pasta + '/'\n",
    "        img_Name = os.listdir(dir_Name)\n",
    "        #shuffle(img_Name)\n",
    "            \n",
    "        for i in range(max_items):\n",
    "            if(img_Name[i][0]==\".\"):\n",
    "                img_Name[i]=img_Name[i][2:]\n",
    "            name = dir_Name + img_Name[i]\n",
    "            list_Imgs.append(cv2.imread(name))\n",
    "            list_Names.append(name)\n",
    "            \n",
    "    for img in list_Imgs:\n",
    "        list_Matrix.append(computa_descritores(img))\n",
    "    \n",
    "    tup = Tuple(list_Names, np.concatenate(list_Matrix)) \n",
    "    return tup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de dados *Caltech101* está organizada em várias subpastas, cada uma contendo objetos de uma categoria específica. Vamos trabalhar inicialmente com as pastas `[\"faces\", \"garfield\", \"platypus\", \"nautilus\", \"elephant\", \"gerenuk\"]`. Chame sua função para estas pastas e guarde os resultados obtidos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = [\"Faces\", \"garfield\", \"platypus\", \"nautilus\", \"elephant\", \"gerenuk\"]\n",
    "descriptor = le_descritores_imagens(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2 - Criação do vocabulário e histograma\n",
    "\n",
    "A criação do vocabulário de padrões visuais é feita usando um algoritmo de *clustering*. Este algoritmo identifica agrupamentos de padrões visuais e retorna, para cada agrupamento, um padrão representante (chamado de centróide por ele ser a média de todos os padrões do agrupamento). Grosso modo, cada centróide representa um conjunto de padrões muito similares, logo poderíamos substituí-los pelo centróide.\n",
    "\n",
    "A biblioteca *scikit-learn* já possui uma implementação do algoritmo *KMeans* que pode ser usada para identificar estes padrões. Veja [neste link](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) a documentação e um exemplo de uso.\n",
    "\n",
    "Nesta parte do roteiro iremos executar a segunda parte do algoritmo: iremos criar o vocabulário e uma função que cria o histograma de padrões visuais.\n",
    "\n",
    "**Exercício**: crie uma função `def cria_vocabulario(descritores, sz=300)` que aplica o algoritmo acima e devolve uma tupla contendo a matriz com cada centróide em uma linha e o objeto `KMeans` criado. Note que a matriz deverá ter `sz` linhas (valor padrão 300) e o mesmo número de colunas dos descritores computados na parte anterior. Você deverá chamar esta função com a matriz de descritores criada na parte anterior.\n",
    "\n",
    "Chamaremos esta tupla nas próximas funções de vocabulário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def cria_vocabulario(descritores, sz = 300):                \n",
    "\n",
    "    Tuple = namedtuple('Tupla', 'matrix kmeans')\n",
    "    kmeans = KMeans(n_clusters = sz, random_state=0).fit(descritores)\n",
    "    tup = Tuple(kmeans.cluster_centers_ , kmeans)\n",
    "\n",
    "    return tup\n",
    "vocabulario = cria_vocabulario(descriptor.matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício**: crie uma função `def representa_histograma(img, vocab)` que recebe uma imagem e um vocabulário e devolve um histograma que a represente. Se você estiver em dúvida como isto deve ser feito, consulte os slides desta aula.\n",
    "\n",
    "**Dica**: o objeto `KMeans` criado na função anterior já possui uma função que calcula as distâncias até cada centróide. Consulte [sua documentação](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.transform) para entender como usá-la. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representa_histograma(img, vocab):\n",
    "    img = cv2.imread(img)\n",
    "    desc = computa_descritores(img)\n",
    "    \n",
    "    dist = vocab.kmeans.predict(desc)\n",
    "    \n",
    "    list_freq = [0] * 300\n",
    "    \n",
    "    for i in dist:\n",
    "        list_freq[i] += 1\n",
    "   \n",
    "    return list_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste sua função com alguma das imagens do *Caltech101*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 13,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 12,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 11,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 15,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 10,\n",
       " 47,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 29,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 13,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 14,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 12,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 13,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 41,\n",
       " 4,\n",
       " 10,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 13,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 11,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 37,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 12,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 14,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 16,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 13,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 11,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 10,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 28,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 10,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 10,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representa_histograma(descriptor.listNames[0], vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3 - Similaridade entre imagens\n",
    "\n",
    "Na última parte criamos uma função que representa uma imagem como um histograma de padrões visuais. Agora nos resta comparar duas imagens e criar um ranqueamento de quais imagens do banco de dados são mais parecidas com uma imagem de busca.\n",
    "\n",
    "**Exercício**: Um método comum para comparação de histogramas é a utilização da distância $\\chi^2$. Escreva abaixo sua fórmula e interprete-a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/184101/comparing-two-histograms-using-chi-square-distance\n",
    "\n",
    "(1/2) (∑((xi−yi)**2)/(xi+yi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício**: o OpenCV já possui uma função de comparação de histogramas. Qual é ela? Como usá-la para computar a distância $\\chi^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.opencv.org/3.1.0/d6/dc7/group__imgproc__hist.html#gga994f53817d621e2e4228fc646342d386aa88d6751fb2bb79e07aa8c8717fda881\n",
    "\n",
    "cv2.HISTCMP_CHISQR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi(hist1,hist2):\n",
    "    hist1 = np.array(hist1)\n",
    "    hist2 = np.array(hist2)\n",
    "    dist = 0.5* np.sum((hist1-hist2)**2/hist1)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4 - juntando tudo\n",
    "\n",
    "Vamos agora juntar todas as partes criadas anteriormente na versão $0.5$ de nosso buscador. Para cada pasta processada na parte 1, \n",
    "\n",
    "1. escolha uma imagem que não foi usada na determinação do vocabulário\n",
    "2. compute a distância dela para todas as imagens do vocabulário\n",
    "3. Mostre as três imagens com menor distância.\n",
    "\n",
    "Note que os passos acima incluem representar cada imagem do vocabulário como um histograma. Tome cuidado para não fazer isto mais de uma vez. \n",
    "\n",
    "Faça seu código de maneira modular, de maneira que para realizar a busca você apenas chame uma função. Você pode supor que esta função recebe como entrada qualquer objeto retornado pelas funções das etapas anteriores. \n",
    "\n",
    "**Exercício**: mostre, visualmente, os resultados de três buscas feitas com seu trabalho e comente os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# busca 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# busca 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# busca 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comente seus resultados aqui*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
